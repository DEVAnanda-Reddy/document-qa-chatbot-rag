{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d1987a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\devan\\AppData\\Roaming\\Python\\Python313\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "539d1b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs loaded: 108\n",
      "1  Battery Management Systems \n",
      "Table of Contents        Page Number \n",
      " \n",
      "1. Introduction          - 2 \n",
      "2. Battery Management System       - 13 \n",
      "3. Associated Components of BMS      - 17 \n",
      "4. Functioning of BMS        - 25 \n",
      "5. Types of BMS         - 30 \n",
      "6. Wireless Distributed Battery Management System \n"
     ]
    }
   ],
   "source": [
    "PDF_FOLDER = Path(\"pdf_data\")\n",
    "\n",
    "documents = []\n",
    "for pdf in PDF_FOLDER.glob(\"*.pdf\"):\n",
    "    loader = PyPDFLoader(str(pdf))\n",
    "    documents.extend(loader.load())\n",
    "\n",
    "print(\"PDFs loaded:\", len(documents))\n",
    "print(documents[0].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af85a6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning done\n",
      "1 Battery Management Systems Table of Contents Page Number 1. Introduction - 2 2. Battery Management System - 13 3. Associated Components of BMS - 17 4. Functioning of BMS - 25 5. Types of BMS - 30 6. Wireless Distributed Battery Management System (wBMS) - 37 7. Adoption of AI technologies in Batter\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"[\\x00-\\x1f\\x7f-\\x9f]\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "cleaned_documents = [\n",
    "    Document(\n",
    "        page_content=clean_text(doc.page_content),\n",
    "        metadata=doc.metadata\n",
    "    )\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "print(\"Cleaning done\")\n",
    "print(cleaned_documents[0].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8bce12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 321\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "recursive_chunks = splitter.split_documents(cleaned_documents)\n",
    "print(\"Total chunks:\", len(recursive_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e692ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devan\\AppData\\Local\\Temp\\ipykernel_4516\\3895874714.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings_model = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123af3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed chunks: 321\n"
     ]
    }
   ],
   "source": [
    "vectorstore = FAISS.from_documents(\n",
    "    documents=recursive_chunks,\n",
    "    embedding=embeddings_model\n",
    ")\n",
    "\n",
    "print(\"Indexed chunks:\", vectorstore.index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23424b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b1c4e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\devan\\AppData\\Local\\Temp\\ipykernel_4516\\1502179629.py:13: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "model_id = \"google/flan-t5-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=300\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e88d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(context: str, question: str) -> str:\n",
    "    return f\"\"\"\n",
    "You are a technical assistant.\n",
    "\n",
    "Using ONLY the information in the context, answer the question.\n",
    "Combine duplicate or similar points into ONE clear answer.\n",
    "Do NOT repeat sentences.\n",
    "Do NOT add extra explanations.\n",
    "If the answer is not present at all, respond with exactly:\n",
    "\"Not found in the provided document.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Final Answer (one paragraph only):\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f820acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_answer(answer: str) -> str:\n",
    "    answer = answer.strip()\n",
    "\n",
    "    # Remove duplicate lines\n",
    "    lines = list(dict.fromkeys(answer.splitlines()))\n",
    "    answer = \" \".join(lines)\n",
    "\n",
    "    # Normalize spaces\n",
    "    answer = \" \".join(answer.split())\n",
    "\n",
    "    return answer\n",
    "def ask_question(question: str) -> str:\n",
    "    docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    prompt = build_prompt(context, question)\n",
    "    raw_answer = llm.invoke(prompt)\n",
    "\n",
    "    return clean_answer(raw_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22bc63d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor fusion technology is just like a \"coach\" because it is capable of kneading sensors with different abilities into a united team of players that can work together and complement each other to win the game(7).\n"
     ]
    }
   ],
   "source": [
    "print(ask_question(\"What is sensor fusion?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bfce2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A distributed BMS incorporates all the electronic hardware on a control bo ard placed directly on the cell or module that is being monitored. This alleviates the bulk of the cabling to a few sensor wires and communication wires between adjacent BMS modules. Consequently, each BMS is more self -contained, and handles computations and communications as required. However, despite this apparent simplicity, this integrated affect the cell, and balances them to ensure the same voltage across cells. It is an embedded system, that has a number of electron ic components on a circuit board. This system comprises of purpose built electronics along with purpose built software to enable a specific applications(13). BMS is responsible for thermal management of the battery and monitors its temperature continuously. If required, BMS can adjust cooling and trigger other safety mechanisms to cease operations and minimize the mechanisms to cease operations and minimize the risks. Importance of BMS: The main function of BMS is to ensure that the battery is protected and any operation out of its safety limit is prevented. It monitors the battery packâ€™s state of charge (SOC) along with the state of health. BMS also manages the battery optimization via cell balancing that improves the life of the battery in the long run. The BMS will also monitor voltage, different temperature parameters, and coolant flow.\n"
     ]
    }
   ],
   "source": [
    "print(ask_question(\"What is distributed BMS?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c11e32e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    \"\"\"\n",
    "    Command-line chatbot for document-based question answering.\n",
    "    Type 'exit' to stop.\n",
    "    \"\"\"\n",
    "    print(\"PDF Q&A Chatbot is ready.\")\n",
    "    print(\"Ask questions based on the document. Type 'exit' to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_question = input(\"User: \").strip()\n",
    "\n",
    "        if user_question.lower() in [\"exit\", \"quit\", \"q\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        if not user_question:\n",
    "            print(\"Chatbot: Please ask a valid question.\\n\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            answer = ask_question(user_question)\n",
    "            print(f\"\\nChatbot: {answer}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Chatbot: An error occurred while processing your question.\")\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d06f2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Q&A Chatbot is ready.\n",
      "Ask questions based on the document. Type 'exit' to quit.\n",
      "\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "chatbot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6622cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local(\"faiss_index\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda Base (LangChain)",
   "language": "python",
   "name": "anaconda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
